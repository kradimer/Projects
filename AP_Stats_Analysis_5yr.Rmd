---
title: "AP Statistics Data Analysis"
author: "Kelly Radimer"
date: "Dec 16, 2020"
output: word_document
---

## Introduction

The intention of this study is to build a model that students can use to predict their AP Exam Score based on the most relevant test scores. The data used comes from my own students for the years 2016-2020. The majority (approximately 85%) of the students in the class are high school seniors, with the remainder being juniors (14%), and sophomores (1%).  AP Exam scores range between 1 and 5, and chapter test scores range from 0 to 40. The Chapters correspond with The Practice of Statistics, 4th edition, by Starnes, Yates and Moore. For each test, there are two different forms that are alternated from year to year, but the question type and difficulty level are consistent from year to year.

## Data Wrangling

Load all relevant packages: 

```{r}
library(pacman)
p_load(dplyr, ggplot2, readxl, stringr, MASS, GGally)
```

Upload my grade books and student AP Exam scores:

```{r}
for (i in 15:19) {
  fn <- paste0("./data/",i,i+1," AP Stats S1 Gradebook.xls")
  nam <- paste("S1Gradebook", i,i+1, sep = "")
  assign(nam, read_excel(fn, col_names = TRUE, skip=1, sheet = "Test"))
}
```

```{r}
for (i in 15:19) {
  fn <- paste0("./data/",i,i+1," AP Stats S2 Gradebook.xls")
  nam <- paste("S2Gradebook",i,i+1, sep = "")
  assign(nam, read_excel(fn, col_names = TRUE, skip=1,sheet = "Test"))
}
```

```{r}
for (i in 16:20) {
  fn <- paste0("./data/20",i," AP Exam Results.xls")
  nam <- paste("APExam20",i, sep = "")
  assign(nam, read_excel(fn, col_names = TRUE, skip=1))
  assign(nam, get(nam) %>% dplyr::select(Name, Score))
}
```

Filter out the blank rows and students who dropped the class:

```{r}
for(i in 15:19) {
  nam <- paste0("S1Gradebook",i,i+1) 
  assign(nam, get(nam) %>%
  filter(!is.na(Name)) %>%
  filter(Percent!=0) %>%
  filter(Name!="Name"))
  }
```

```{r}
for(i in 15:19) {
  nam <- paste0("S2Gradebook",i,i+1) 
  assign(nam, get(nam) %>%
  filter(!is.na(Name)) %>%
  filter(Percent!=0) %>%
  filter(Name!="Name"))
  }
```


Join the two semesters together, add a column for AP Exam score, and filter out the students who didn't take the AP Exam:

```{r}
for (i in 15:19) {
  nam <- paste0("combined",i,i+1)
  df1 <- paste0("S1Gradebook",i,i+1)
  df2 <- paste0("S2Gradebook",i,i+1)
  assign(nam, full_join(get(df1),get(df2), by=c("Name","ID")))
}
```

```{r}
for (i in 15:19) {
  nam <- paste0("combined",i,i+1)
  scores <- paste0("APExam20", i+1)
  assign(nam, get(scores) %>% right_join(get(nam), by="Name"))
}
```

```{r}
for (i in 15:19) {
  nam <- paste0("combined",i,i+1)
  assign(nam, get(nam) %>% filter(!is.na(Score)))
}
```

Rename the relevant variables so that they are the same for all 5 dataframes:

```{r}
for (i in 1:12) {
  colnames(combined1516)[grepl(paste0('Ch ',i,' '),colnames(combined1516))] <- paste0('ch',i)
}

for (i in 1:12) {
  colnames(combined1617)[grepl(paste0('Ch ',i,' '),colnames(combined1617))] <- paste0('ch',i)
}

for (i in 1:12) {
  colnames(combined1718)[grepl(paste0('Ch ',i,' '),colnames(combined1718))] <- paste0('ch',i)
}

for (i in 1:12) {
  colnames(combined1819)[grepl(paste0('Ch ',i,' '),colnames(combined1819))] <- paste0('ch',i)
}

for (i in 1:12) {
  colnames(combined1920)[grepl(paste0('Ch ',i,' '),colnames(combined1920))] <- paste0('ch',i)
}
```

Select AP Exam Scores and chapter test scores (note that due to the pandemic we did not cover Ch 11 and 12 in 2020):

```{r}
combined1516 <- combined1516 %>%
  dplyr::select(Score,ch1,ch2,ch3,ch4,ch5,ch6,ch7,ch8,ch9,ch10,ch11,ch12)

combined1617 <- combined1617 %>%
  dplyr::select(Score,ch1,ch2,ch3,ch4,ch5,ch6,ch7,ch8,ch9,ch10,ch11,ch12)

combined1718 <- combined1718 %>%
  dplyr::select(Score,ch1,ch2,ch3,ch4,ch5,ch6,ch7,ch8,ch9,ch10,ch11,ch12)

combined1819 <- combined1819 %>%
  dplyr::select(Score,ch1,ch2,ch3,ch4,ch5,ch6,ch7,ch8,ch9,ch10,ch11,ch12)

combined1920 <- combined1920 %>%
  dplyr::select(Score,ch1,ch2,ch3,ch4,ch5,ch6,ch7,ch8,ch9,ch10)
```

Some of the scores are classified as character variables rather than numeric, so we will convert them all to numeric.

```{r message=FALSE, warning=FALSE}
dm<-data.matrix(combined1516)
df16<-as.data.frame(dm)
dm<-data.matrix(combined1617)
df17<-as.data.frame(dm)
dm<-data.matrix(combined1718)
df18<-as.data.frame(dm)
dm<-data.matrix(combined1819)
df19<-as.data.frame(dm)
dm<-data.matrix(combined1920)
df20<-as.data.frame(dm)
```

Now we can bind all 5 years into a single data frame and write it into a csv file that we can use for future analysis.

```{r}
dat <- bind_rows(df16,df17,df18,df19,df20)
#write.csv(dat, "CombinedAPStatsData16_20.csv")
```



## Exploratory Data Analysis

Now that we have all of our data tidied, let's do some exploratory data analysis. Here are the paired scatterplots, density curves and correlations for the first seven variables: 

```{r message=FALSE, warning=FALSE, fig.width=9, fig.height=8}
ggpairs(dat, columns = 1:7)
```

Each of these variables has a moderately strong positive association with the other variables. This makes sense intuitively, as students who do well on one test tend to do well on other tests. Correlation of each test with the AP Exam score is fairly consistent across the first six tests, with the highest correlation being with Chapters 1-3.

Most of the chapter tests have unimodal, left-skewed distributions, since the majority of students tend to perform well on tests. We can see that students tend to perform especially well on the Chapter 2 test, as the scores are concentrated in the 30's with many students achieving a perfect score of 40/40. Chapter 2 covers Normal Distributions and measures of relative standing. It is largely computational and easy for students to pick up. Chapter 4 was noticeably more difficult, with a very low density of students achieving perfect scores. Chapter 4 is about designing studies, with a large amount of new vocabulary for students to learn, and almost entirely conceptual.

The distribution of AP Exam scores is trimodal, with increasingly large peaks at 3, 4 and 5. There are a small number of outliers with scores of 1 and 2.

```{r message=FALSE, warning=FALSE, fig.width=9, fig.height=8}
ggpairs(dat, columns = c(1,8:13))
```

Chapters 7-12 have fairly similar relationships with score as the first six chapters. Chapter 7 has a noticeably higher correlation. This makes sense because Chapter 7 is where students are first introduced to sampling distributions, a concept that is key to understanding all the subsequent chapters.  Chapter 7 also has greater variability in scores than most of the other chapters. 

Chapter 8 in particular has a very low standard deviation. Chapter 8 is about confidence intervals. Most students are able to thoroughly understand the basic mechanics and interpretations of confidence intervals, giving them a solid score. The chapter 8 test has one high-level challenge question asking students to use a simulated sampling distribution to construct a confidence interval for a different parameter, which only a very small number of students are able to successfully complete, which is why the average is high but there are few perfect scores. Chapter 8 also has a low outlier, with a test score of 0. This is a student who was caught cheating on the test.

Chapter 10 has a particularly low correlation with AP Exam Score. I believe the reason for this is that Chapter 10 is taken with a partner, so scores may not be reflective of a student's actual knowledge.


## Variable selection

Let's now create a model that students can use to predict their AP Exam score. We will start out with their grades for all twelve tests, and then use Baysian Model selection to create a parsimonious model.  

```{r}
model_full=lm(Score~ch1+ch2+ch3+ch4+ch5+ch6+ch7+ch8+ch9+ch10+ch11+ch12, data=dat)
summary(model_full)
```
Now we will use the Akaike Information Criterion to strike a balance between over- and under-fitting our model by identifying the model with the lowest AIC value.

```{r}
model_AIC=stepAIC(model_full, direction="backward", k=2, trace=TRUE)
```

Bayesian stepwise AIC elimination indicates that we can make our best predictions of a student's AP Exam score using their grades from the chapter 1, 2, 3, 7, 8 and 12 tests.  We noted earlier that Chapter 7 is particularly significant in terms of the material covered.  It is interesting to see that Ch 12 (the last chapter of the book) is significant. Chapter 12 is about Inference for Regression and Transformations to Achieve Linearity, topics that are not typically represented heavily on the AP Exam.  Given that the majority of students in AP Statistics are seniors, who have already received their acceptance to college, a possible explanation for the importance of Chapter 12 is that it provides an indicator of how strongly a student has fallen prey to "senioritis."  A student who is able to maintain their focus through the final chapter of the book is probably also going to perform better on the AP Exam.

```{r}
summary(model_AIC)
```

This provides us with the regression equation:

Predicted AP Exam Score = -2.46733 + 0.03182(ch1) + 0.03058(ch2) + 0.03334(ch3) + 0.05268(ch7) + 0.02479(ch8) + 0.0259(ch12).  

Approximately 60% of the variability in AP Exam scores is accounted for by our model. On average, our predictions of AP Exam score are off by 0.607. 

Let's have a look at the residual plot.

```{r,fig.width=4, fig.height=3}
ggplot(model_AIC, aes(x=.fitted, y=.resid))+geom_point()+geom_hline(yintercept = 0, linetype="dashed")
```

The five diagonal stripes are the result of the fact that students can only receive 1, 2, 3, 4, or 5 on the exam, with the leftmost stripe corresponding with students who obtained a 1, up through the rightmost stripe corresponding with students who obtained a 5. We can see that for most students the prediction was within 1 of their actual score.  

There is one notable outlier, the student who received a score 3.5 below what was predicted. This was a high-achieving senior whose chosen college would not accept AP credit, so he decided to take a nap during the exam. The student with the residual of -2 might have been in a similar situation. Otherwise, our model seems to have performed well. Adding a dummy variable to indicate whether the student had committed to a college that wouldn't accept AP Exam credit prior to taking the exam would likely make our predictions even more accurate.

Now let's look at the distribution of the residuals.

```{r,fig.width=4, fig.height=3}
hist(model_AIC$residuals)
qqnorm(model_AIC$residuals)
```

The residuals are fairly close to Normal in their distribution, with the two aforementioned under-achieving students ( with residuals of -3.5 and -2) creating a slight left skew. 
